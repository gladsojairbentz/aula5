import ollama
 
# Inicializar o modelo
modelo = ollama.Modelo("gpt-2")
 
# Executar o modelo
modelo.executar()
 
# Loop do chatbot
while True:
    entrada_usuario = input("Você: ")
    if entrada_usuario.lower() == "sair":
        break
    
    # Fazer inferência
    resposta = modelo.prever(entrada_usuario)
    
    print(f"Chatbot: {resposta}")